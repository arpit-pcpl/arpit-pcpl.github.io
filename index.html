<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Speechmatics Flow - Agent Chat</title>
  <style>
    body { font-family: Arial; margin: 2rem; }
    input, button { font-size: 1rem; margin: 0.5rem 0; width: 100%; padding: 0.5rem; }
    pre { background: #f0f0f0; padding: 1rem; height: 300px; overflow-y: auto; white-space: pre-wrap; }
  </style>
</head>
<body>
  <h2>ğŸ¤ Speechmatics Flow v1 - Agent Chat</h2>
  <label for="jwt">ğŸ” Enter Temporary JWT Token:</label>
  <input type="text" id="jwt" placeholder="Paste your Speechmatics JWT here" />
  
  <button id="start">â–¶ï¸ Start Conversation</button>
  <button id="stop" disabled>â¹ï¸ Stop</button>
  
  <pre id="output"></pre>

  <script>
    const startBtn = document.getElementById("start");
    const stopBtn = document.getElementById("stop");
    const jwtInput = document.getElementById("jwt");
    const output = document.getElementById("output");

    let ws, audioContext, processor, input, stream;

    function log(msg) {
      output.textContent += msg + '\n';
      output.scrollTop = output.scrollHeight;
    }

    startBtn.onclick = async () => {
      const jwt = jwtInput.value.trim();
      if (!jwt) {
        alert("Please enter a valid JWT.");
        return;
      }

      startBtn.disabled = true;
      stopBtn.disabled = false;
      const WS_URL = `wss://flow.api.speechmatics.com/v1/flow?jwt=${jwt}`;

      log("ğŸ”Œ Connecting to Speechmatics Flow...");
      ws = new WebSocket(WS_URL);
      ws.binaryType = "arraybuffer";

      ws.onopen = async () => {
        log("âœ… WebSocket connected.");

        // Send StartConversation
        ws.send(JSON.stringify(
          {
            "message": "StartConversation",
            "audio_format": {
              "type": "raw",
              "encoding": "pcm_f32le",
              "sample_rate": 44100
            },
            "conversation_config": {
              "template_id": "default"
            }
          }
        ));

        // Start audio stream
        stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        audioContext = new AudioContext({ sampleRate: 44100 });
        input = audioContext.createMediaStreamSource(stream);
        processor = audioContext.createScriptProcessor(4096, 1, 1);

        processor.onaudioprocess = e => {
          const float32Data = e.inputBuffer.getChannelData(0);
          if (ws.readyState === WebSocket.OPEN) {
            ws.send(float32Data.buffer);
          }
        };

        input.connect(processor);
        processor.connect(audioContext.destination);
      };

      ws.onmessage = async (event) => {
      if (typeof event.data === "string") {
        const data = JSON.parse(event.data);
        if (data.message === "Transcript") {
          const content = data.transcript?.alternatives?.[0]?.content;
          if (content) log("ğŸ—£ï¸ " + content);
        } else {
          log("ğŸ“¥ " + JSON.stringify(data));
        }
      } else if (event.data instanceof ArrayBuffer) {
        // Handle audio binary data from Flow
        playAudioChunk(event.data);
      }
    };

      ws.onerror = (err) => log("âŒ WebSocket error: " + err.message);
      ws.onclose = () => log("ğŸ”Œ Connection closed.");
    };

    function playAudioChunk(arrayBuffer) {
      const audioContext = new (window.AudioContext || window.webkitAudioContext)();
      const dataView = new DataView(arrayBuffer);
      const float32Array = new Float32Array(dataView.byteLength / 2);
    
      for (let i = 0; i < float32Array.length; i++) {
        const int16 = dataView.getInt16(i * 2, true); // little-endian
        float32Array[i] = int16 / 32768;
      }
    
      const audioBuffer = audioContext.createBuffer(1, float32Array.length, 44100);
      audioBuffer.copyToChannel(float32Array, 0);
    
      const source = audioContext.createBufferSource();
      source.buffer = audioBuffer;
      source.connect(audioContext.destination);
      source.start();
    }

    stopBtn.onclick = () => {
      stopBtn.disabled = true;
      startBtn.disabled = false;

      if (ws && ws.readyState === WebSocket.OPEN) {
        ws.close();
      }
      if (processor) processor.disconnect();
      if (input) input.disconnect();
      if (audioContext) audioContext.close();
      if (stream) stream.getTracks().forEach(t => t.stop());

      log("ğŸ›‘ Stopped conversation.");
    };
  </script>
</body>
</html>
